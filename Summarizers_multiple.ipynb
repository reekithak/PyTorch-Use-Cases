{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summarizers_multiple.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQbp_1Auhuoq",
        "colab_type": "text"
      },
      "source": [
        "**Bert-Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9iv7osIhsYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1wOJbbPYUfh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "f9b782a1-e414-4f85-ab47-1d68f70d909b"
      },
      "source": [
        "pip install bert-extractive-summarizer\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-extractive-summarizer in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from bert-extractive-summarizer) (2.2.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (from bert-extractive-summarizer) (2.11.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from bert-extractive-summarizer) (0.22.2.post1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (1.18.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (47.3.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->bert-extractive-summarizer) (2.0.3)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (0.7)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (20.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (0.0.43)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers->bert-extractive-summarizer) (0.1.91)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->bert-extractive-summarizer) (0.15.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->bert-extractive-summarizer) (1.6.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2020.6.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers->bert-extractive-summarizer) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers->bert-extractive-summarizer) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->bert-extractive-summarizer) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->bert-extractive-summarizer) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwOqSEr5YemI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from summarizer import Summarizer"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qstgFj1_V3fr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e29ae185-3081-473d-f2a9-05358efc449a"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnFm-aluV91v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mylines = []   \n",
        "file = 'drive/My Drive/nlp.txt'                          "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5eO8dGoXin8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open (file, 'rt') as myfile:\n",
        "    for myline in myfile:                \n",
        "        mylines.append(myline)           \n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRYzHWWlXrcS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "6d0b15da-d636-436a-b605-7b9ac53a7c12"
      },
      "source": [
        "mylines"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural-language generation (NLG) is a software process that transforms structured data into natural language. It can be used to produce long form content for organizations to automate custom reports, as well as produce custom content for a web or mobile application. It can also be used to generate short blurbs of text in interactive conversations (a chatbot) which might even be read out by a text-to-speech system.\\n',\n",
              " '\\n',\n",
              " 'Automated NLG can be compared to the process humans use when they turn ideas into writing or speech. Psycholinguists prefer the term language production for this process, which can also be described in mathematical terms, or modeled in a computer for psychological research. NLG systems can also be compared to translators of artificial computer languages, such as decompilers or transpilers, which also produce human-readable code generated from an intermediate representation. Human languages tend to be considerably more complex and allow for much more ambiguity and variety of expression than programming languages, which makes NLG more challenging.\\n',\n",
              " '\\n',\n",
              " 'NLG may be viewed as the opposite of natural-language understanding: whereas in natural-language understanding, the system needs to disambiguate the input sentence to produce the machine representation language, in NLG the system needs to make decisions about how to put a concept into words. The practical considerations in building NLU vs. NLG systems are not symmetrical. NLU needs to deal with ambiguous or erroneous user input, whereas the ideas the system wants to express through NLG are generally known precisely. NLG needs to choose a specific, self-consistent textual representation from many potential representations, whereas NLU generally tries to produce a single, normalized representation of the idea expressed.[1]\\n',\n",
              " '\\n',\n",
              " 'NLG has existed for a long time[when?] but commercial NLG technology has only recently[when?] become widely available. NLG techniques range from simple template-based systems like a mail merge that generates form letters, to systems that have a complex understanding of human grammar. NLG can also be accomplished by training a statistical model using machine learning, typically on a large corpus of human-written texts.[2]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq4FCtgeXzpf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "0f4b3aeb-9f0e-4503-ec87-f1dbaadb34cb"
      },
      "source": [
        "#print(\"Enter the words? , Enter No to stop the inputs\")\n",
        "wrd_list = []\n",
        "x='yes'\n",
        "while x.lower()!=\"no\":\n",
        "    usr_input = input(\"Enter your word: \")\n",
        "    wrd_list.append(usr_input)\n",
        "    print(\"Do You wanto to continue?\")\n",
        "    x = input()\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your word: and\n",
            "Do You wanto to continue?\n",
            "yes\n",
            "Enter your word: nlg\n",
            "Do You wanto to continue?\n",
            "no\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Hvbl8CPfPdy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "7470df39-0308-4c4f-fe9b-b69c41932533"
      },
      "source": [
        "file = open(\"drive/My Drive/copy.txt\", \"w\")     #new extracted file will seve in copy.txt file\n",
        "iter_= 1\n",
        "for i in mylines:\n",
        "     for wrd in wrd_list:\n",
        "        \n",
        "         if wrd in i.lower():\n",
        "            print(wrd)\n",
        "            file.write(i) \n",
        "            print(\"Recognised \"+str(iter_))\n",
        "            iter_+=1\n",
        "file.close()  \n",
        "\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nlg\n",
            "Recognised 1\n",
            "and\n",
            "Recognised 2\n",
            "nlg\n",
            "Recognised 3\n",
            "and\n",
            "Recognised 4\n",
            "nlg\n",
            "Recognised 5\n",
            "and\n",
            "Recognised 6\n",
            "nlg\n",
            "Recognised 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfPN8N5wX6tV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new=[]\n",
        "with open ('drive/My Drive/copy.txt', 'rt') as txtfile: \n",
        "    for line in txtfile:               \n",
        "        new.append(line)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6_be-nvYAO-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "7e5354ac-11ec-47b1-cf60-f9050357b1bc"
      },
      "source": [
        "txt = ''.join(str(i) for i in new)\n",
        "txt"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'Natural-language generation (NLG) is a software process that transforms structured data into natural language. It can be used to produce long form content for organizations to automate custom reports, as well as produce custom content for a web or mobile application. It can also be used to generate short blurbs of text in interactive conversations (a chatbot) which might even be read out by a text-to-speech system.\\nAutomated NLG can be compared to the process humans use when they turn ideas into writing or speech. Psycholinguists prefer the term language production for this process, which can also be described in mathematical terms, or modeled in a computer for psychological research. NLG systems can also be compared to translators of artificial computer languages, such as decompilers or transpilers, which also produce human-readable code generated from an intermediate representation. Human languages tend to be considerably more complex and allow for much more ambiguity and variety of expression than programming languages, which makes NLG more challenging.\\nAutomated NLG can be compared to the process humans use when they turn ideas into writing or speech. Psycholinguists prefer the term language production for this process, which can also be described in mathematical terms, or modeled in a computer for psychological research. NLG systems can also be compared to translators of artificial computer languages, such as decompilers or transpilers, which also produce human-readable code generated from an intermediate representation. Human languages tend to be considerably more complex and allow for much more ambiguity and variety of expression than programming languages, which makes NLG more challenging.\\nNLG may be viewed as the opposite of natural-language understanding: whereas in natural-language understanding, the system needs to disambiguate the input sentence to produce the machine representation language, in NLG the system needs to make decisions about how to put a concept into words. The practical considerations in building NLU vs. NLG systems are not symmetrical. NLU needs to deal with ambiguous or erroneous user input, whereas the ideas the system wants to express through NLG are generally known precisely. NLG needs to choose a specific, self-consistent textual representation from many potential representations, whereas NLU generally tries to produce a single, normalized representation of the idea expressed.[1]\\nNLG may be viewed as the opposite of natural-language understanding: whereas in natural-language understanding, the system needs to disambiguate the input sentence to produce the machine representation language, in NLG the system needs to make decisions about how to put a concept into words. The practical considerations in building NLU vs. NLG systems are not symmetrical. NLU needs to deal with ambiguous or erroneous user input, whereas the ideas the system wants to express through NLG are generally known precisely. NLG needs to choose a specific, self-consistent textual representation from many potential representations, whereas NLU generally tries to produce a single, normalized representation of the idea expressed.[1]\\nNLG has existed for a long time[when?] but commercial NLG technology has only recently[when?] become widely available. NLG techniques range from simple template-based systems like a mail merge that generates form letters, to systems that have a complex understanding of human grammar. NLG can also be accomplished by training a statistical model using machine learning, typically on a large corpus of human-written texts.[2]NLG has existed for a long time[when?] but commercial NLG technology has only recently[when?] become widely available. NLG techniques range from simple template-based systems like a mail merge that generates form letters, to systems that have a complex understanding of human grammar. NLG can also be accomplished by training a statistical model using machine learning, typically on a large corpus of human-written texts.[2]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hIvh53WYLTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Summarizer()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXNF3CkiYzfQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "1e608cc5-5526-4566-c3f8-cd63644fc60e"
      },
      "source": [
        "res = model(txt,min_length=60)\n",
        "fin = ''.join(res)\n",
        "fin"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'Natural-language generation (NLG) is a software process that transforms structured data into natural language. Automated NLG can be compared to the process humans use when they turn ideas into writing or speech. Human languages tend to be considerably more complex and allow for much more ambiguity and variety of expression than programming languages, which makes NLG more challenging. NLG may be viewed as the opposite of natural-language understanding: whereas in natural-language understanding, the system needs to disambiguate the input sentence to produce the machine representation language, in NLG the system needs to make decisions about how to put a concept into words. The practical considerations in building NLU vs. NLG systems are not symmetrical.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp548ed9hG_C",
        "colab_type": "text"
      },
      "source": [
        "**PY Summarizer - LSTM (seq2seq)** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT2m2I6WZA49",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "cf810c6c-ca5b-4294-d0d6-c34cc610754e"
      },
      "source": [
        "pip install pysummarization"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pysummarization\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/38/131f8574e0e12f27fa2d35b11a91055a67c8e55b205a505669c6df7881cb/pysummarization-1.1.4.tar.gz (57kB)\n",
            "\r\u001b[K     |█████▊                          | 10kB 14.1MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 1.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pysummarization) (1.18.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from pysummarization) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->pysummarization) (1.12.0)\n",
            "Building wheels for collected packages: pysummarization\n",
            "  Building wheel for pysummarization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysummarization: filename=pysummarization-1.1.4-cp36-none-any.whl size=58337 sha256=b7ee90616b63633c1e788c39bcd0ec398c787d9e7ffa4657e099187c61cb0cc2\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/43/1c/575498c1b472967ba3f395edd26826fa095b52cee9553e52ce\n",
            "Successfully built pysummarization\n",
            "Installing collected packages: pysummarization\n",
            "Successfully installed pysummarization-1.1.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBAmiijdhfOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pysummarization.nlpbase.auto_abstractor import AutoAbstractor\n",
        "from pysummarization.tokenizabledoc.simple_tokenizer import SimpleTokenizer\n",
        "from pysummarization.abstractabledoc.top_n_rank_abstractor import TopNRankAbstractor"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuB0P8nUhFeN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "c7f824e5-4477-412a-f45e-27074581550d"
      },
      "source": [
        "txt"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'Natural-language generation (NLG) is a software process that transforms structured data into natural language. It can be used to produce long form content for organizations to automate custom reports, as well as produce custom content for a web or mobile application. It can also be used to generate short blurbs of text in interactive conversations (a chatbot) which might even be read out by a text-to-speech system.\\nAutomated NLG can be compared to the process humans use when they turn ideas into writing or speech. Psycholinguists prefer the term language production for this process, which can also be described in mathematical terms, or modeled in a computer for psychological research. NLG systems can also be compared to translators of artificial computer languages, such as decompilers or transpilers, which also produce human-readable code generated from an intermediate representation. Human languages tend to be considerably more complex and allow for much more ambiguity and variety of expression than programming languages, which makes NLG more challenging.\\nAutomated NLG can be compared to the process humans use when they turn ideas into writing or speech. Psycholinguists prefer the term language production for this process, which can also be described in mathematical terms, or modeled in a computer for psychological research. NLG systems can also be compared to translators of artificial computer languages, such as decompilers or transpilers, which also produce human-readable code generated from an intermediate representation. Human languages tend to be considerably more complex and allow for much more ambiguity and variety of expression than programming languages, which makes NLG more challenging.\\nNLG may be viewed as the opposite of natural-language understanding: whereas in natural-language understanding, the system needs to disambiguate the input sentence to produce the machine representation language, in NLG the system needs to make decisions about how to put a concept into words. The practical considerations in building NLU vs. NLG systems are not symmetrical. NLU needs to deal with ambiguous or erroneous user input, whereas the ideas the system wants to express through NLG are generally known precisely. NLG needs to choose a specific, self-consistent textual representation from many potential representations, whereas NLU generally tries to produce a single, normalized representation of the idea expressed.[1]\\nNLG may be viewed as the opposite of natural-language understanding: whereas in natural-language understanding, the system needs to disambiguate the input sentence to produce the machine representation language, in NLG the system needs to make decisions about how to put a concept into words. The practical considerations in building NLU vs. NLG systems are not symmetrical. NLU needs to deal with ambiguous or erroneous user input, whereas the ideas the system wants to express through NLG are generally known precisely. NLG needs to choose a specific, self-consistent textual representation from many potential representations, whereas NLU generally tries to produce a single, normalized representation of the idea expressed.[1]\\nNLG has existed for a long time[when?] but commercial NLG technology has only recently[when?] become widely available. NLG techniques range from simple template-based systems like a mail merge that generates form letters, to systems that have a complex understanding of human grammar. NLG can also be accomplished by training a statistical model using machine learning, typically on a large corpus of human-written texts.[2]NLG has existed for a long time[when?] but commercial NLG technology has only recently[when?] become widely available. NLG techniques range from simple template-based systems like a mail merge that generates form letters, to systems that have a complex understanding of human grammar. NLG can also be accomplished by training a statistical model using machine learning, typically on a large corpus of human-written texts.[2]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HmL97KWhRdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auto_ab = AutoAbstractor()\n",
        "auto_ab.tokenizable_doc = SimpleTokenizer()\n",
        "auto_ab.delimiter_list = [\".\", \"\\n\"]\n",
        "abstractable_doc = TopNRankAbstractor()\n",
        "result_dict = auto_ab.summarize(txt, abstractable_doc)\n",
        "restxt = str(result_dict['summarize_result'])\n",
        "try:\n",
        "    restxt = restxt.replace('[','') ; restxt = restxt.replace(']','') ; restxt = restxt.replace('\\\\n','') ; restxt = restxt.replace(\"'\",'')\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00I0solHhb89",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "02e19a2d-766f-4915-ce4a-00a3aa9f2318"
      },
      "source": [
        "summ = [str(x) for x in restxt.split('.')]\n",
        "msumm=[]\n",
        "for l in summ:\n",
        "    l = l.replace(',',''); #l =l.replace(\" \",\"\")\n",
        "    \n",
        "    msumm.append(l)\n",
        "finstr = '.'.join(str(i) for i in msumm) + '.'\n",
        "finstr"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'Natural-language generation (NLG) is a software process that transforms structured data into natural language.  It can be used to produce long form content for organizations to automate custom reports as well as produce custom content for a web or mobile application.  It can also be used to generate short blurbs of text in interactive conversations (a chatbot) which might even be read out by a text-to-speech system. Automated NLG can be compared to the process humans use when they turn ideas into writing or speech.  Psycholinguists prefer the term language production for this process which can also be described in mathematical terms or modeled in a computer for psychological research.  NLG systems can also be compared to translators of artificial computer languages such as decompilers or transpilers which also produce human-readable code generated from an intermediate representation. Automated NLG can be compared to the process humans use when they turn ideas into writing or speech.  Psycholinguists prefer the term language production for this process which can also be described in mathematical terms or modeled in a computer for psychological research.  NLG systems can also be compared to translators of artificial computer languages such as decompilers or transpilers which also produce human-readable code generated from an intermediate representation. NLG has existed for a long timewhen? but commercial NLG technology has only recentlywhen? become widely available..'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYQTBg0_hk4j",
        "colab_type": "text"
      },
      "source": [
        "**NLTK Summarizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZCsvzSqho7F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "0a8e4774-4477-4577-b0bd-e264fa25db28"
      },
      "source": [
        "pip install text-summarizer"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting text-summarizer\n",
            "  Downloading https://files.pythonhosted.org/packages/ca/b7/1e5cbe26751fbc53c81283c41dcc832709c199e41be54342e80f1e4549eb/text_summarizer-0.0.6.tar.gz\n",
            "Building wheels for collected packages: text-summarizer\n",
            "  Building wheel for text-summarizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for text-summarizer: filename=text_summarizer-0.0.6-cp36-none-any.whl size=6932 sha256=5706bb1c66978ffeee2a65353522afe97bc2894ed5ab19d4efc6c2a978fc867d\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/9e/ef/8de724dae779a0eec305ab2793a61f019b8d1f149ccf0e23e9\n",
            "Successfully built text-summarizer\n",
            "Installing collected packages: text-summarizer\n",
            "Successfully installed text-summarizer-0.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVJscJRyidz-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "4d5251e6-9f43-491a-a61f-25a8838860ab"
      },
      "source": [
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize, sent_tokenize \n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0b2CkmNiwCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopWords = set(stopwords.words(\"english\")) \n",
        "words = word_tokenize(txt) \n",
        "freqTable = dict()"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWoHrSg4jO9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freqTable = dict() \n",
        "for word in words: \n",
        "    word = word.lower() \n",
        "    if word in stopWords: \n",
        "        continue\n",
        "    if word in freqTable: \n",
        "        freqTable[word] += 1\n",
        "    else: \n",
        "        freqTable[word] = 1"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5IdIa58jqib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = sent_tokenize(txt) \n",
        "sentenceValue = dict()"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN_82fQujy41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for sentence in sentences: \n",
        "    for word, freq in freqTable.items(): \n",
        "        if word in sentence.lower(): \n",
        "            if sentence in sentenceValue: \n",
        "                sentenceValue[sentence] += freq \n",
        "            else: \n",
        "                sentenceValue[sentence] = freq "
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg2U8nmvj2ZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sumValues = 0\n",
        "for sentence in sentenceValue: \n",
        "    sumValues += sentenceValue[sentence]"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA-X8solj37e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  average = int(sumValues / len(sentenceValue)) \n",
        "except ZeroDivisionError:\n",
        "  average= 0 "
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6GHVxGyj8Zf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "004e8890-83c9-46aa-f84f-7c6f54784b16"
      },
      "source": [
        "summary = '' \n",
        "for sentence in sentences: \n",
        "    if (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)): \n",
        "        summary += \" \" + sentence \n",
        "summary"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "' Psycholinguists prefer the term language production for this process, which can also be described in mathematical terms, or modeled in a computer for psychological research. NLG systems can also be compared to translators of artificial computer languages, such as decompilers or transpilers, which also produce human-readable code generated from an intermediate representation. Human languages tend to be considerably more complex and allow for much more ambiguity and variety of expression than programming languages, which makes NLG more challenging. Psycholinguists prefer the term language production for this process, which can also be described in mathematical terms, or modeled in a computer for psychological research. NLG systems can also be compared to translators of artificial computer languages, such as decompilers or transpilers, which also produce human-readable code generated from an intermediate representation. Human languages tend to be considerably more complex and allow for much more ambiguity and variety of expression than programming languages, which makes NLG more challenging. NLU needs to deal with ambiguous or erroneous user input, whereas the ideas the system wants to express through NLG are generally known precisely. NLG needs to choose a specific, self-consistent textual representation from many potential representations, whereas NLU generally tries to produce a single, normalized representation of the idea expressed. NLU needs to deal with ambiguous or erroneous user input, whereas the ideas the system wants to express through NLG are generally known precisely. NLG needs to choose a specific, self-consistent textual representation from many potential representations, whereas NLU generally tries to produce a single, normalized representation of the idea expressed. NLG techniques range from simple template-based systems like a mail merge that generates form letters, to systems that have a complex understanding of human grammar. NLG can also be accomplished by training a statistical model using machine learning, typically on a large corpus of human-written texts. NLG techniques range from simple template-based systems like a mail merge that generates form letters, to systems that have a complex understanding of human grammar. NLG can also be accomplished by training a statistical model using machine learning, typically on a large corpus of human-written texts.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rVEGlfYj-XL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}